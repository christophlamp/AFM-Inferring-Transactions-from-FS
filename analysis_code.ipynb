{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case = 'Case1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory to where the file is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\path'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\chris\\Desktop\\MA\\coding\\coding\\m6\\centrality_analysis\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive edgelist from File edge.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "DG=nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reader(filename2):\n",
    "    for (lineno, line) in enumerate(open(filename2)):\n",
    "        if lineno > 0: # skip header\n",
    "            yield line\n",
    "\n",
    "filename2 = \"edges.csv\"\n",
    "(from_, to_, capac) = zip(*( row for row in csv.reader(reader(filename2))))\n",
    "\n",
    "l_edges = list(zip(from_, to_, capac))\n",
    "\n",
    "for f,t, c in l_edges:\n",
    "    DG.add_edge(f,t)\n",
    "    DG.edge[f][t]['capacity'] = int(c)\n",
    "    DG.edge[f][t]['weight'] = int(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive nodelist from File nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reader(filename):\n",
    "    for (lineno, line) in enumerate(open(filename)):\n",
    "        if lineno > 0: # skip header\n",
    "            yield line\n",
    "\n",
    "filename = \"nodes.csv\"\n",
    "(l_nodes, change) = zip(*( row for row in csv.reader(reader(filename))))\n",
    "\n",
    "d_nodes = dict(zip(l_nodes, change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive two incidence matrices from DG() for (A) weighted, export to incidencematrix.csv and (B) unweighted, to use for max-flow algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "///weighted Incidence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incidence_matrix(A, nodelist=None, edgelist=None, \n",
    "                     oriented=True, weight='weight'):\n",
    "    if nodelist is None:\n",
    "        nodelist = l_nodes\n",
    "    if edgelist is None:\n",
    "        edgelist = l_edges\n",
    "    A = np.zeros((len(nodelist),len(edgelist)))\n",
    "    node_index = dict( (node,i) for i,node in enumerate(nodelist) )\n",
    "    for ei,e in enumerate(edgelist):\n",
    "        (u,v) = e[:2]\n",
    "        if u == v: continue  # self loops give zero column\n",
    "        try:\n",
    "            ui = node_index[u]\n",
    "            vi = node_index[v]\n",
    "        except KeyError:\n",
    "            raise NetworkXError('node %s or %s in edgelist '\n",
    "                                'but not in nodelist\"%(u,v)')\n",
    "        if weight is None:\n",
    "            wt = 1\n",
    "        else:\n",
    "            if DG.is_multigraph():\n",
    "                ekey = e[2]\n",
    "                wt = DG[u][v][ekey].get(weight,1)\n",
    "            else:\n",
    "                wt = DG[u][v].get(weight,1)\n",
    "        if oriented:\n",
    "            A[ui,ei] = -wt\n",
    "            A[vi,ei] = wt\n",
    "        else:\n",
    "            A[ui,ei] = wt\n",
    "            A[vi,ei] = wt\n",
    "    return np.asmatrix(wA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wA = incidence_matrix(\"wA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(A)\n",
    "df.to_csv(\"01_incidencematrix.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "///unweighted Incidence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incidence_matrix(A, nodelist=None, edgelist=None, \n",
    "                     oriented=True, weight=None):\n",
    "    if nodelist is None:\n",
    "        nodelist = l_nodes\n",
    "    if edgelist is None:\n",
    "        edgelist = l_edges\n",
    "    A = np.zeros((len(nodelist),len(edgelist)))\n",
    "    node_index = dict( (node,i) for i,node in enumerate(nodelist) )\n",
    "    for ei,e in enumerate(edgelist):\n",
    "        (u,v) = e[:2]\n",
    "        if u == v: continue  # self loops give zero column\n",
    "        try:\n",
    "            ui = node_index[u]\n",
    "            vi = node_index[v]\n",
    "        except KeyError:\n",
    "            raise NetworkXError('node %s or %s in edgelist '\n",
    "                                'but not in nodelist\"%(u,v)')\n",
    "        if weight is None:\n",
    "            wt = 1\n",
    "        else:\n",
    "            if DG.is_multigraph():\n",
    "                ekey = e[2]\n",
    "                wt = DG[u][v][ekey].get(weight,1)\n",
    "            else:\n",
    "                wt = DG[u][v].get(weight,1)\n",
    "        if oriented:\n",
    "            A[ui,ei] = -wt\n",
    "            A[vi,ei] = wt\n",
    "        else:\n",
    "            A[ui,ei] = wt\n",
    "            A[vi,ei] = wt\n",
    "    return np.asmatrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = incidence_matrix(\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run centrality measures on nx.DG (directed graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree centrality; depends on the amount of connections (the same for all cases as the network is the same unless certain edges are zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree = nx.degree_centrality(DG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betweennes centrality; accounts acting as a bridge, gatekeeper or broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betweenness = nx.betweenness_centrality(DG, k=None, normalized=True, weight='weight', endpoints=False, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closeness centrality; A central node is one, that is close, on average, to other nodes => use inverse of weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(DG, u=None, distance='weight', normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionary for export as 02_centrality.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "output = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in (degree, betweenness, closeness):\n",
    "    for key, value in d.items():\n",
    "        output[key].append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centrality = pd.DataFrame.from_dict(output, orient=\"index\")\n",
    "centrality.to_csv(\"02_centrality.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate max flow of the network (add [S] and [T], add outer arcs to model network flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reader(filename):\n",
    "    for (lineno, line) in enumerate(open(filename)):\n",
    "        if lineno > 0: # skip header\n",
    "            yield line\n",
    "\n",
    "filename = \"nodes.csv\"\n",
    "(l_nodes, change) = zip(*( row for row in csv.reader(reader(filename))))\n",
    "\n",
    "d_nodes = dict(zip(l_nodes, change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arcs based on whether the change in balance is negative (CR) or positive (DR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in d_nodes.items():\n",
    "    \n",
    "    if float(v) < 0:\n",
    "        DG.add_edge('S',k)\n",
    "        #nx.set_edge_attributes(DG, 'capacity', {('S',k): abs(int(v))})\n",
    "\n",
    "    if float(v) > 0:\n",
    "        DG.add_edge(k,'T')\n",
    "        #nx.set_edge_attributes(DG, 'capacity', {(k, 'T'): abs(int(v))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run algorithm to determine max flow of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of nodes: 16\n",
      "no. of edges: 29\n",
      "maximum flow: 580\n",
      "minimum cut:  580\n"
     ]
    }
   ],
   "source": [
    "print('no. of nodes:',DG.number_of_nodes())\n",
    "print('no. of edges:',DG.number_of_edges())\n",
    "print('maximum flow:',nx.maximum_flow_value(DG, s='S', t='T'))\n",
    "print('minimum cut: ',nx.minimum_cut_value(DG, s=\"S\", t=\"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maximum_flow = nx.maximum_flow(DG, 'S', 'T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive vector y from max-flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytemp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, z, y in l_edges:\n",
    "    try:\n",
    "        ytemp.append(maximum_flow[1][x][z])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(ytemp).reshape(len(l_edges),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate implied changes in balances; y * A = impx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy vector with dimension [no. of transactions] by [1] to multiply with weighted incidence matrix. Yields implied changes (impx) in balances to be used for calculating a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy = np.empty(len(l_edges))\n",
    "dummy.fill(1)\n",
    "dummy_vector = dummy.reshape(len(l_edges), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impx = wA * dummy_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive actual x (actx) from d_nodes, deduct implied x (impx) and export it as 03_impx.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_change = []\n",
    "for value in change:\n",
    "    int_change.append(int(value))\n",
    "actx = np.array(int_change).reshape(len(l_nodes), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = actx - impx\n",
    "deltasqrd = np.square(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_actx = pd.DataFrame(data = actx, index = l_nodes)\n",
    "df_impx = pd.DataFrame(data = impx, index = l_nodes)\n",
    "df_delta = pd.DataFrame(data = delta, index = l_nodes)\n",
    "df_deltasqrd = pd.DataFrame(data = deltasqrd, index = l_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_output = pd.concat([df_actx, df_impx, df_delta, df_deltasqrd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_output.columns = ['actx','impx','delta','deltasqrd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_output.to_csv(\"03_impx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
